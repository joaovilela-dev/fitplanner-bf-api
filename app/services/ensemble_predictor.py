"""
Sistema ENSEMBLE de predi√ß√£o de Body Fat - V3 SAFE MODE
Arquitetura profissional com ML em quarentena.

üîí MODO SAFE (Produ√ß√£o):
    - Regras (60%) + Textura (40%)
    - ML n√£o influencia o resultado final
    - ML registrado apenas para an√°lise

üß™ MODO EXPERIMENTAL (Pesquisa):
    - ML inclu√≠do no ensemble (apenas para compara√ß√£o)
    - Dispon√≠vel via flag use_experimental_ml=True
"""

import numpy as np
import os


# ===================================
# CONFIGURA√á√ÉO GLOBAL
# ===================================
USE_EXPERIMENTAL_ML = os.getenv("USE_EXPERIMENTAL_ML", "false").lower() == "true"


def ensemble_predict_body_fat(
    ml_prediction: float,
    rules_prediction: float,
    texture_data: dict,
    bmi: float,
    sex: str,
    measurements: dict,
    ratios: dict,
    use_experimental_ml: bool = USE_EXPERIMENTAL_ML
) -> dict:
    """
    Predi√ß√£o ENSEMBLE V3 - SAFE MODE
    
    üîí MODO SAFE (padr√£o):
        - BF Final = Regras (60%) + Textura (40%)
        - ML registrado mas n√£o influencia
        - Maior confiabilidade
    
    üß™ MODO EXPERIMENTAL:
        - BF Final inclui ML no ensemble
        - Apenas para an√°lise e compara√ß√£o
    
    Args:
        ml_prediction: Predi√ß√£o do modelo ML
        rules_prediction: Predi√ß√£o baseada em regras
        texture_data: Dados de an√°lise de textura
        bmi: √çndice de Massa Corporal
        sex: "male" ou "female"
        measurements: Medi√ß√µes corporais
        ratios: Raz√µes corporais
        use_experimental_ml: Se True, inclui ML no c√°lculo final
    
    Returns:
        {
            "final_prediction": float,
            "safe_prediction": float (sempre sem ML),
            "experimental_prediction": float (com ML),
            "mode": "SAFE" ou "EXPERIMENTAL",
            ...
        }
    """
    
    adjustments = []
    
    # ===================================
    #  PREDI√á√ÉO BASEADA EM TEXTURA
    # ===================================
    from app.services.texture_analyzer import estimate_bf_from_definition
    texture_prediction = estimate_bf_from_definition(texture_data, sex, bmi)
    
    # ===================================
    #  AN√ÅLISE DE QUALIDADE DAS MEDI√á√ïES
    # ===================================
    
    shoulder_width = measurements.get("shoulder_width", 0.4)
    hip_width = measurements.get("hip_width", 0.3)
    waist_to_shoulder = ratios.get("waist_to_shoulder", 0.6)
    volume_indicator = measurements.get("volume_indicator", 0.15)
    
    # Detectar medi√ß√µes suspeitas (fundo branco, detec√ß√£o parcial)
    measurements_suspicious = (
        shoulder_width < 0.25 or
        hip_width < 0.15 or
        waist_to_shoulder > 0.80
    )
    
    if measurements_suspicious:
        adjustments.append(
            f"‚ö†Ô∏è Medidas antropom√©tricas suspeitas (shoulder={shoulder_width:.3f}, hip={hip_width:.3f})"
        )
        print(f"   ‚ö†Ô∏è MEDIDAS SUSPEITAS (shoulder={shoulder_width:.3f}, hip={hip_width:.3f})")
    
    # ===================================
    #  CALCULAR CONFIAN√áA DE CADA M√âTODO
    # ===================================
    
    # Textura: Confian√ßa da an√°lise de imagem
    texture_confidence = texture_data.get("confidence", 0.5)
    
    # Regras: Confian√ßa baseada em consist√™ncia dos dados
    rules_confidence = 0.7
    
    # ML: Sempre registrado, mas confian√ßa depende do modo
    ml_confidence = _calculate_ml_confidence(measurements, ratios, bmi)
    
    # ===================================
    #  AJUSTES DIN√ÇMICOS DE CONFIAN√áA
    # ===================================
    
    # Extrair m√©tricas relevantes
    definition_score = texture_data.get("definition_score", 0.5)
    abs_visibility = texture_data.get("abs_visibility", 0.5)
    central_fat = texture_data.get("central_fat", 0.5)
    
    # --- CASO 1: ATLETA ---
    is_athlete = (
        definition_score > 0.65 and
        abs_visibility > 0.60 and
        central_fat < 0.45 and
        20 <= bmi <= 26
    )
    
    if is_athlete:
        adjustments.append("üèãÔ∏è F√≠sico atl√©tico - Priorizando an√°lise visual")
        print("   üèãÔ∏è ATLETA DETECTADO")
        texture_confidence = min(texture_confidence * 1.4, 1.0)
        rules_confidence *= 0.9
    
    # --- CASO 2: SOBREPESO ---
    is_overweight = (
        bmi > 28 and
        waist_to_shoulder > 0.65
    )
    
    if is_overweight:
        adjustments.append("üìà Sobrepeso - Priorizando regras fisiol√≥gicas")
        print("   üìà SOBREPESO DETECTADO")
        rules_confidence = min(rules_confidence * 1.3, 1.0)
        texture_confidence *= 0.85
    
    # --- CASO 3: MEDIDAS SUSPEITAS ---
    if measurements_suspicious:
        adjustments.append("üì∏ Detec√ß√£o parcial - Priorizando an√°lise visual")
        print("   üì∏ PRIORIZANDO TEXTURA")
        texture_confidence = min(texture_confidence * 1.6, 1.0)
        rules_confidence *= 0.7
    
    # --- CASO 4: BAIXA QUALIDADE DE IMAGEM ---
    if texture_confidence < 0.4:
        adjustments.append("‚ö†Ô∏è Baixa qualidade de imagem - Priorizando regras")
        print("   ‚ö†Ô∏è BAIXA QUALIDADE")
        rules_confidence = min(rules_confidence * 1.2, 1.0)
        texture_confidence *= 0.8
    
    # ===================================
    #  MODO SAFE 
    # ===================================
    
    # Normalizar confian√ßas (SEM ML)
    total_safe = rules_confidence + texture_confidence
    safe_rules_weight = rules_confidence / total_safe
    safe_texture_weight = texture_confidence / total_safe
    
    # Calcular BF SAFE (apenas Regras + Textura)
    safe_prediction = (
        rules_prediction * safe_rules_weight +
        texture_prediction * safe_texture_weight
    )
    
    print(f"\nüîí MODO SAFE - Predi√ß√µes:")
    print(f"   Regras:  {rules_prediction:.1f}% (peso {safe_rules_weight:.2f})")
    print(f"   Textura: {texture_prediction:.1f}% (peso {safe_texture_weight:.2f})")
    print(f"   ‚Üí SAFE:  {safe_prediction:.1f}%")
    
    # ===================================
    #  MODO EXPERIMENTAL 
    # ===================================
    
    experimental_prediction = None
    experimental_weights = None
    ml_divergence = abs(ml_prediction - rules_prediction)
    
    if use_experimental_ml:
        # Ajustar confian√ßa do ML baseado em diverg√™ncia
        if ml_divergence > 10:
            adjustments.append(f"‚ö†Ô∏è ML diverge {ml_divergence:.1f}% das regras")
            ml_confidence *= 0.3  # Reduzir drasticamente
        
        # Normalizar confian√ßas (COM ML)
        total_exp = ml_confidence + rules_confidence + texture_confidence
        exp_ml_weight = ml_confidence / total_exp
        exp_rules_weight = rules_confidence / total_exp
        exp_texture_weight = texture_confidence / total_exp
        
        experimental_prediction = (
            ml_prediction * exp_ml_weight +
            rules_prediction * exp_rules_weight +
            texture_prediction * exp_texture_weight
        )
        
        experimental_weights = {
            "ml": round(exp_ml_weight, 3),
            "rules": round(exp_rules_weight, 3),
            "texture": round(exp_texture_weight, 3)
        }
        
        print(f"\nüß™ MODO EXPERIMENTAL - Predi√ß√µes:")
        print(f"   ML:      {ml_prediction:.1f}% (peso {exp_ml_weight:.2f})")
        print(f"   Regras:  {rules_prediction:.1f}% (peso {exp_rules_weight:.2f})")
        print(f"   Textura: {texture_prediction:.1f}% (peso {exp_texture_weight:.2f})")
        print(f"   ‚Üí EXPERIMENTAL: {experimental_prediction:.1f}%")
    
    # ===================================
    #  VALIDA√á√ÉO FISIOL√ìGICA FINAL
    # ===================================
    from app.services.bf_validator import validate_and_adjust_bf
    
    # Validar predi√ß√£o SAFE
    validation = validate_and_adjust_bf(
        bf_prediction=safe_prediction,
        bmi=bmi,
        sex=sex,
        measurements=measurements,
        ratios=ratios
    )
    
    final_prediction = validation["adjusted_bf"]
    
    if validation["was_adjusted"]:
        adjustments.append(
            f"üîß Valida√ß√£o: {safe_prediction:.1f}% ‚Üí {final_prediction:.1f}% "
            f"({validation['reason']})"
        )
        print(f"   üîß VALIDA√á√ÉO: {safe_prediction:.1f}% ‚Üí {final_prediction:.1f}%")
    
    print(f"   ‚úÖ FINAL: {final_prediction:.1f}%")
    
    # ===================================
    #  CONFIAN√áA FINAL
    # ===================================
    
    # Calcular diverg√™ncia entre m√©todos principais
    predictions_safe = [rules_prediction, texture_prediction]
    pred_std_safe = np.std(predictions_safe)
    
    # Confian√ßa baseada em concord√¢ncia
    agreement = 1.0 - (pred_std_safe / 20)
    avg_confidence = (rules_confidence + texture_confidence) / 2
    
    final_confidence = (agreement * 0.6 + avg_confidence * 0.4)
    final_confidence = max(0.3, min(final_confidence, 1.0))
    
    #  ML como DETECTOR DE CONFIAN√áA
    if ml_divergence > 15:
        final_confidence *= 0.85  # Reduzir confian√ßa se ML diverge muito
        adjustments.append(f" Confian√ßa reduzida devido √† diverg√™ncia do ML ({ml_divergence:.1f}%)")
    
    # ===================================
    #  RESULTADO COM MODO SAFE
    # ===================================
    
    mode = "EXPERIMENTAL" if use_experimental_ml else "SAFE"
    
    result = {
        # Predi√ß√µes finais
        "final_prediction": round(experimental_prediction if use_experimental_ml else final_prediction, 1),
        "safe_prediction": round(final_prediction, 1),  # Sempre dispon√≠vel
        "experimental_prediction": round(experimental_prediction, 1) if experimental_prediction else None,
        
        # Predi√ß√µes individuais
        "ml_prediction": round(ml_prediction, 1),
        "rules_prediction": round(rules_prediction, 1),
        "texture_prediction": round(texture_prediction, 1),
        
        # Pesos SAFE
        "safe_weights": {
            "rules": round(safe_rules_weight, 3),
            "texture": round(safe_texture_weight, 3)
        },
        
        # Pesos EXPERIMENTAL (se aplic√°vel)
        "experimental_weights": experimental_weights,
        
        # Metadados
        "mode": mode,
        "confidence": round(final_confidence, 2),
        "confidence_level": _get_confidence_level(final_confidence),
        "method_used": f"Ensemble V3 - {mode} MODE (Rules + Texture)",
        "adjustments": adjustments,
        "texture_analysis": texture_data,
        
        # ML como detector de confian√ßa
        "ml_analysis": {
            "prediction": round(ml_prediction, 1),
            "divergence_from_rules": round(ml_divergence, 1),
            "confidence_impact": "reduced" if ml_divergence > 15 else "neutral",
            "status": "quarantine" if not use_experimental_ml else "active"
        },
        
        # Casos especiais
        "special_cases": {
            "is_athlete": is_athlete,
            "is_overweight": is_overweight,
            "measurements_suspicious": measurements_suspicious,
            "low_image_quality": texture_confidence < 0.4
        }
    }
    
    return result


def _calculate_ml_confidence(measurements: dict, ratios: dict, bmi: float) -> float:
    """
    Calcula confian√ßa do modelo ML.
     V3: Confian√ßa reduzida por padr√£o (ML em quarentena)
    """
    
    confidence = 0.5  #  Reduzido de 1.0 para 0.5
    
    # BMI t√≠pico: 18-35
    if bmi < 18 or bmi > 35:
        confidence *= 0.8
    
    # Waist ratio t√≠pico: 0.40-0.75
    waist_ratio = ratios.get("waist_to_shoulder", 0.6)
    if waist_ratio < 0.35 or waist_ratio > 0.80:
        confidence *= 0.85
    
    # Volume indicator t√≠pico: 0.12-0.30
    volume = measurements.get("volume_indicator", 0.15)
    if volume < 0.10 or volume > 0.35:
        confidence *= 0.9
    
    return confidence


def _get_confidence_level(confidence: float) -> str:
    """Retorna n√≠vel textual de confian√ßa"""
    if confidence >= 0.85:
        return "Muito Alta"
    elif confidence >= 0.70:
        return "Alta"
    elif confidence >= 0.55:
        return "M√©dia"
    elif confidence >= 0.40:
        return "Baixa"
    else:
        return "Muito Baixa"